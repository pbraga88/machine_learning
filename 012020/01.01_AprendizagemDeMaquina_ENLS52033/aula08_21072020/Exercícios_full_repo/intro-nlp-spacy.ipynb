{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Intro to Natural Language Processing with Python\n\n## Info\n- Scott Bailey (CIDR), *scottbailey@stanford.edu*\n- Javier de la Rosa (CIDR), *versae@stanford.edu*\n\n\n## What are we covering today?\n- What is NLP?\n- Options for NLP in Python\n- Tokenization\n- Part of Speech Tagging\n- Named Entity Recognition\n- Word transformations\n- Readability indices"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Goals\n\nBy the end of the workshop, we hope you'll have a basic understanding of natural language processing, and enough familiarity with one NLP package, SpaCy, to perform basic NLP tasks like tokenization and part of speech tagging. Through analyzing presidential speeches, we also hope you'll understand how these basic tasks open up a number of possibilities for textual analysis, such as readability indices. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## What is NLP\n\nNLP stands for Natual Language Processing and it involves a huge variety of tasks such as:\n- Automatic summarization.\n- Coreference resolution.\n- Discourse analysis.\n- Machine translation.\n- Morphological segmentation.\n- Named entity recognition.\n- Natural language understanding.\n- Part-of-speech tagging.\n- Parsing.\n- Question answering.\n- Relationship extraction.\n- Sentiment analysis.\n- Speech recognition.\n- Topic segmentation.\n- Word segmentation.\n- Word sense disambiguation.\n- Information retrieval.\n- Information extraction.\n- Speech processing.\n\nOne of the key ideas is to be able to process text without reading it."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## NLP in Python\n\nPython is builtin with a very mature regular expression library, which is the building block of natural language processing. However, more advanced tasks need different libraries. Traditionally, in the Python ecosystem the Natural Language Processing Toolkit, abbreviated as `NLTK`, has been until recently the only working choice. Now, though, there are a number of choices based on different technologies and approaches\n\nWe'll a solution that appeared relatively recently, called `spaCy`, and it is much faster than NLTK since is written in a pseudo-C Python language optimized for speed called Cython.\n\nBoth these libraries are complex and there exist wrappers around them to simplify their APIs. The two more popular are `Textblob` for NLTK and CLiPS Parser, and `textacy` for spaCy. In this workshop we will be using spaCy with a touch of textacy thrown in at the very end."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install spacy",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7fdecda4d898>, 'Connection to webproxy timed out. (connect timeout=15)')': /simple/spacy/\u001b[0m\n\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7fdecda4d358>, 'Connection to webproxy timed out. (connect timeout=15)')': /simple/spacy/\u001b[0m\n\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7fdecda4d4a8>, 'Connection to webproxy timed out. (connect timeout=15)')': /simple/spacy/\u001b[0m\n\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7fdecda4d390>, 'Connection to webproxy timed out. (connect timeout=15)')': /simple/spacy/\u001b[0m\n\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7fdecda4d400>, 'Connection to webproxy timed out. (connect timeout=15)')': /simple/spacy/\u001b[0m\n\u001b[31mERROR: Could not find a version that satisfies the requirement spacy (from versions: none)\u001b[0m\n\u001b[31mERROR: No matching distribution found for spacy\u001b[0m\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import spacy",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!python -m spacy download en",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Collecting en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0\n\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n\u001b[K    100% |████████████████████████████████| 37.4MB 5.9MB/s ta 0:00:011    30% |█████████▊                      | 11.3MB 4.1MB/s eta 0:00:07    39% |████████████▊                   | 14.9MB 5.9MB/s eta 0:00:04\n\u001b[31mException:\nTraceback (most recent call last):\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/pip/_internal/cli/base_command.py\", line 176, in main\n    status = self.run(options, args)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/pip/_internal/commands/install.py\", line 346, in run\n    session=session, autobuilding=True\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/pip/_internal/wheel.py\", line 848, in build\n    assert building_is_possible\nAssertionError\u001b[0m\n\u001b[33mYou are using pip version 19.0, however version 19.0.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n\u001b[?25h",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "nlp = spacy.load('en')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# helper functions\nimport requests\n\ndef get_text(url):\n    return requests.get(url).text\n\ndef get_speech(url):\n    page = get_text(url)\n    full_text = page.split('\\n')\n    return \" \".join(full_text[2:])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "clinton_url = \"https://raw.githubusercontent.com/sul-cidr/python_workshops/master/data/clinton2000.txt\"\nclinton_speech = get_speech(clinton_url)\nclinton_speech",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "doc = nlp(clinton_speech)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Tokenization\n\nIn NLP, the act of splitting text is called tokenization, and each of the individual chunks is called a token. Therefore, we can talk about word tokenization or sentence tokenization depending on what it is that we need to divide the text into."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# word level\nfor token in doc:\n    print(token.text)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# sentence level\nfor sent in doc.sents:\n    print(sent)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# noun phrases\nfor phrase in doc.noun_chunks:\n    print(phrase)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Part of Speech Tagging\n\nSpaCy also allows you to perform Part-Of-Speech tagging, a kind of grammatical chunking, out of the box. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# simple part of speech tag\nfor token in doc:\n    print(token.text, token.pos_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# detailed tag\n# For what these tags mean, you might check out http://www.clips.ua.ac.be/pages/mbsp-tags\nfor token in doc:\n    print(token.text, token.tag_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# syntactic dependency\nfor token in doc:\n    print(token.text, token.dep_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# visualizing the sentence\nfrom spacy import displacy",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "first_sent = list(doc.sents)[0]\nfirst_sent",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "single_doc = nlp(str(first_sent))\noptions = {\"compact\": True, 'bg': '#09a3d5',\n           'color': 'white', 'font': 'Source Sans Pro'}\ndisplacy.render(single_doc, style=\"dep\", jupyter=True, options=options)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<div style=\"font-size: 1em; margin: 1em 0 1em 0; border: 1px solid #86989B; background-color: #f7f7f7; padding: 0;\">\n<p style=\"margin: 0; padding: 0.1em 0 0.1em 0.5em; color: white; border-bottom: 1px solid #86989B; font-weight: bold; background-color: #AFC1C4;\">\nActivity\n</p>\n<p style=\"margin: 0.5em 1em 0.5em 1em; padding: 0;\">\nWrite a function `count_chars(text)` that receives `text` and returns the total number of characters ignoring spaces and punctuation marks. For example, `count_chars(\"Well, I am not 30 years old.\")` should return `20`.\n<br/>\n* **Hint**: You could count the characters in the words.*\n</p>\n</div>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Solution using two functions, one to get just words without punct, one to get chars\ndef return_words(doc):\n    return [token.text for token in doc if token.pos_ is not 'PUNCT']\n\ndef count_chars(words):\n    return sum(len(w) for w in words)\n\n# count_chars(\"Well, I am not 30 years old.\")\nwords = return_words(nlp(\"Well, I am not 30 years old.\"))\ncount_chars(words)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Named Entity Recognition "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# https://spacy.io/api/annotation#named-entities\n# trained on OntoNotes corpus\nfor ent in doc.ents:\n    print(ent.text, ent.label_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# If you're working on tokens, you can still access entity type\n# Notice, though that the phrase entities are broken up here because we're iterating over tokens\n# https://spacy.io/api/annotation#named-entities\nfor token in doc:\n    if token.ent_type_ is not '':\n        print(token.text, token.ent_type_, \"----------\", spacy.explain(token.ent_type_))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# spacy comes with built in entity visualization\ndisplacy.render(single_doc, style=\"ent\", jupyter=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "next_sent = list(doc.sents)[3]\nnext_doc = nlp(str(next_sent))\ndisplacy.render(next_doc, style=\"ent\", jupyter=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "It is possible to train your own entity recognition model, and to train other types of models in spaCy, but you need sufficient labeled data to make it work well."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Word transformations"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# lemmas\nfor token in doc:\n    print(token.text, token.lemma_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "doc1 = nlp('here are octopi')\nfor token in doc1:\n    print(token.lemma_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "doc1 = nlp('There have been many mice and geese surrounding the pond.')\nfor token in doc1:\n    print(token, token.lemma_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# say we just want to lematize verbs\nfor token in doc:\n    if token.tag_ == \"VBP\":\n        print(token.text, token.lemma_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# If you're using the simple part of speech instead of the tags\nfor token in doc:\n    if token.pos_ == \"VERB\":\n        print(token.text, token.lemma_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# lowercasing\nfor token in doc:\n    print(token.text, token.lower_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Counting"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from collections import Counter",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sample_sents = \"One fish, two fish, red fish, blue fish. One is less than two.\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Create a spacy doc\nnew_doc = nlp(sample_sents)\n\n# Create a list of the words without the punctuation\nwords = [token.text for token in new_doc if token.pos_ is not 'PUNCT']\nwords",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "counter = Counter(words)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "counter.most_common(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "counter[\"fish\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Sentiment Analysis\n\nRight now, spacy doesn't include a model for sentiment analysis. From comments on the spacy github repo, the developers of spacy, Explosion are going to offer sentiment models as part of their commercial offerings.\n\nThey have put out examples for how to do sentiment analysis: \n- https://github.com/explosion/spaCy/blob/master/examples/deep_learning_keras.py\n- https://github.com/explosion/spaCy/blob/master/examples/training/train_textcat.py\n\nBoth of these use some sort of deep learning/neural networks\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<div style=\"font-size: 1em; margin: 1em 0 1em 0; border: 1px solid #86989B; background-color: #f7f7f7; padding: 0;\">\n<p style=\"margin: 0; padding: 0.1em 0 0.1em 0.5em; color: white; border-bottom: 1px solid #86989B; font-weight: bold; background-color: #AFC1C4;\">\nActivity\n</p>\n<p style=\"margin: 0.5em 1em 0.5em 1em; padding: 0;\">\nLet's define the lexicon of a person as the number of different words she uses to speak. Write a function `get_lexicon(text, n)` that receives `text` and `n` and returns the lemmas of nouns, verbs, and adjectives that are used at least `n` times.\n<br/>\n</p>\n</div>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_lexicon(text, n):\n    doc = nlp(text)\n    \n    # return a list of words that have the correct part of speech    \n    words = [token.lemma_ for token in doc if token.pos_ in [\"NOUN\", \"ADJ\", \"VERB\"]]\n    # count the words     \n    counter = Counter(words)\n    # filter by number\n    filtered_words = [word for word in counter if counter[word] > n]\n    return sorted(filtered_words)\n    \nget_lexicon(clinton_speech, 30)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Readability indices\n\nReadability indices are ways of assessing how easy or complex it is to read a particular text based on the words and sentences it has. They usually output scores that correlate with grade levels.\n\nA couple of indices that are presumably easy to calculate are the Auto Readability Index (ARI) and the Coleman-Liau Index:\n\n$$\nARI = 4.71\\frac{chars}{words}+0.5\\frac{words}{sentences}-21.43\n$$\n$$ CL = 0.0588\\frac{letters}{100 words} - 0.296\\frac{sentences}{100words} - 15.8 $$\n\n\nhttps://en.wikipedia.org/wiki/Coleman%E2%80%93Liau_index\n\nhttps://en.wikipedia.org/wiki/Automated_readability_index"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# problem: the tokens in spacy include punctuation. to get this right, we should remove punct\n# we then have to make sure our functions handle lists of words rather than spacy doc objects\n\ndef coleman_liau_index(doc, words):\n    return (0.0588 * letters_per_100(doc)) - (0.296 * sentences_per_100(doc, words)) - 15.8\n\ndef count_chars(words):\n    return sum(len(w) for w in words)\n\ndef sentences_per_100(doc, words):\n    return (len(list(doc.sents)) / len(words)) * 100\n\ndef letters_per_100(words):\n    return (count_chars(words) / len(words)) * 100",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# To get just the words, without punctuation tokens\ndef return_words(doc):\n    return [token.text for token in doc if token.pos_ is not 'PUNCT']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "fancy_doc = nlp(\"Regional ontology, clearly defined by Heidegger, equals, if not surpasses, the earlier work of Heidegger's own mentor, Husserl\")\nfancy_words = return_words(fancy_doc)\nfancy_words",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "coleman_liau_index(fancy_doc, fancy_words)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "doc = nlp(clinton_speech)\nclinton_speech_words = return_words(doc)\ncoleman_liau_index(doc, clinton_speech_words)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<div style=\"font-size: 1em; margin: 1em 0 1em 0; border: 1px solid #86989B; background-color: #f7f7f7; padding: 0;\">\n<p style=\"margin: 0; padding: 0.1em 0 0.1em 0.5em; color: white; border-bottom: 1px solid #86989B; font-weight: bold; background-color: #AFC1C4;\">\nActivity\n</p>\n<p style=\"margin: 0.5em 1em 0.5em 1em; padding: 0;\">\nWrite a function `auto_readability_index(doc)` that receives a spacy `Doc` and returns the Auto Readability Index (ARI) score as defined above. \n<br/>\n* **Hint**: Feel free to use functions we've defined before.*\n   \n</p>\n</div>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def auto_readability_index(doc):\n    words = return_words(doc)\n    chars = count_chars(words)\n    words = len(words)\n    sentences = len(list(doc.sents))\n    return (4.71 * (chars / words)) + (0.5 * (words / sentences)) - 21.43",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "auto_readability_index(fancy_doc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "auto_readability_index(doc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "clinton_url = \"https://raw.githubusercontent.com/sul-cidr/python_workshops/master/data/clinton2000.txt\"\nbush_url = \"https://raw.githubusercontent.com/sul-cidr/python_workshops/master/data/bush2008.txt\"\nobama_url = \"https://raw.githubusercontent.com/sul-cidr/python_workshops/master/data/obama2016.txt\"\ntrump_url = \"https://raw.githubusercontent.com/sul-cidr/python_workshops/master/data/trump.txt\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "clinton_speech = get_speech(clinton_url)\nbush_speech = get_speech(bush_url)\nobama_speech = get_speech(obama_url)\ntrump_speech = get_speech(trump_url)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "speeches = {\n    \"clinton\": nlp(clinton_speech),\n    \"bush\": nlp(bush_speech),\n    \"obama\": nlp(obama_speech),\n    \"trump\": nlp(trump_speech),\n}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"Name\", \"Chars\", \"Words\", \"Unique\", \"Sentences\", sep=\"\\t\")\nfor speaker, speech in speeches.items():\n    words = return_words(speech)\n    print(speaker, count_chars(words), len(words), len(set(words)), len(list(speech.sents)), sep=\"\\t\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<div style=\"font-size: 1em; margin: 1em 0 1em 0; border: 1px solid #86989B; background-color: #f7f7f7; padding: 0;\">\n<p style=\"margin: 0; padding: 0.1em 0 0.1em 0.5em; color: white; border-bottom: 1px solid #86989B; font-weight: bold; background-color: #AFC1C4;\">\nActivity\n</p>\n<p style=\"margin: 0.5em 1em 0.5em 1em; padding: 0;\">\nWrite a function `avg_sentence_length(blob)` that receives a spaCy `doc` and returns the average number of words in a sentence for the doc. You might need to use our `return_words` function.\n</p>\n</div>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# average sentence length\ndef avg_sentence_length(doc):\n    return sum(len(return_words(s)) for s in doc.sents) / len(list(doc.sents))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for speaker, speech in speeches.items():\n    print(speaker, avg_sentence_length(speech))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We might stop to ask why Obama's speech seems to have shorter sentences. Is it deliberate rhetorical choice? Or could it be an issue with the data itself?\n\nIn this case, if we look closely at the txt file, we can see that the transcription of the speech included the world 'applause' as a one word sentence throughout the text. Let's see what happens if we filter that out. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "obama_clean_speech = obama_speech.replace(\"(Applause.)\", \"\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Let's compare lengths of the texts. We should see a difference.\n\nlen(obama_speech), len(obama_clean_speech)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Now let's recheck the average sentence length of Obama's speech.\navg_sentence_length(nlp(obama_clean_speech))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "speeches = {\n    \"clinton\": nlp(clinton_speech),\n    \"bush\": nlp(bush_speech),\n    \"obama\": nlp(obama_clean_speech),\n    \"trump\": nlp(trump_speech),\n}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's write a quick function to get the most common words used by each person"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def most_common_words(doc, n):\n    words = return_words(doc)\n    c = Counter(words)\n    return c.most_common(n)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "for speaker, speech in speeches.items():\n    print(speaker, most_common_words(speech, 10))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can see quickly that we need to remove some of these most common words. To do this, we'll use common lists of stopwords."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "from spacy.lang.en.stop_words import STOP_WORDS\nprint(STOP_WORDS)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# to make sure we've got all the punctuation out and to remove some contractions, we'll have a custom stoplist\ncustom_stopwords = [',', '-', '.', '’s', '-', ' ', '(', ')', '--', '---', 'n’t', ';', \"'s\", \"'ve\", \"  \", \"’ve\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def most_common_words(doc, n):\n    words = [token.text for token in doc if token.pos_ is not 'PUNCT' \n             and token.lower_ not in STOP_WORDS and token.text not in custom_stopwords]\n    c = Counter(words)\n    return c.most_common(n)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for speaker, speech in speeches.items():\n    print(speaker, \": \", most_common_words(speech, 10), \"\\n\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This sort of exploratory work is often the first step in figuring out how to clean a text for text analysis. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's assess the lexical richness, defined as the ratio of number of unique words by the number of total words."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def lexical_richness(doc):\n    words = return_words(doc)\n    return len(set(words)) / len(words)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for speaker, speech in speeches.items():\n    print(speaker, lexical_richness(speech))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's look at the readbility scores for all four speeches now\n\nFor the Automated Readability Index, you can get the appropriate grade level here: https://en.wikipedia.org/wiki/Automated_readability_index"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "for speaker, speech in speeches.items():\n    words = return_words(speech)\n    print(speaker, \"ARI:\", auto_readability_index(speech), \"CL:\", coleman_liau_index(speech, words))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To get some comparison, let's also look at some stats calculated through Textacy. We'll see the ARI and CL scores, which use the same formulas we used. However, you might notice that the scores are different. To understand why, you have to dig into the source code for Textacy, where you'll find that it filters out punctuation in creating the word list, which affects the number of characters. It also lowercases the punctuation-filtered words before creating the set of unique words, decreasing that number as well compared to how we calculated it here. These changes affect both the ARI and CL scores."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install textacy",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import textacy",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# https://en.wikipedia.org/wiki/Coleman%E2%80%93Liau_index\n# https://en.wikipedia.org/wiki/Automated_readability_index\ntxt_speeches = [clinton_speech, bush_speech, obama_clean_speech, trump_speech]\ncorpus = textacy.Corpus('en', txt_speeches)\nfor doc in corpus:\n    stats = textacy.text_stats.TextStats(doc)\n    print({\n        \"ARI\": stats.automated_readability_index,\n        \"CL\": stats.coleman_liau_index,\n        \"stats\": stats.basic_counts\n    })",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Why do we have such a significant difference in the CL scores? Let's look quickly at the textacy implementation: https://github.com/chartbeat-labs/textacy/blob/5927d539dd989c090f8a0b0c06ba40bb204fce82/textacy/text_stats.py#L277"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"Name\", \"Chars\", \"Words\", \"Unique\", \"Sentences\", sep=\"\\t\")\nfor speaker, speech in speeches.items():\n    words = return_words(speech)\n    print(speaker, count_chars(words), len(words), len(set(words)), len(list(speech.sents)), sep=\"\\t\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# clinton, bush, obama, trump\nfor doc in corpus:\n    stats = textacy.text_stats.TextStats(doc)\n    print({\n        \"stats\": stats.basic_counts\n    })",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "Post-workshop eval:\n\nhttps://stanforduniversity.qualtrics.com/jfe/form/SV_aaZ76OCnWDqQbuR"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}