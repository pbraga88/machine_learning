{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset MTCars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operações SQL simples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base **MTCars** https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html já é conhecida, e é bastante utilizada para exemplos de Machine Learning.\n",
    "\n",
    "Mesmo sendo uma base de dados com 32 linhas e 11 colunas, servirá bem para nosso exemplo de uso de consultas SQL a partir do Spark.\n",
    "\n",
    "Vamos fazer algumas atividades com o SparkSQL, siga os exemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster('local').setAppName('PySpark SQL')\n",
    "sc = SparkContext.getOrCreate(conf = conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação do contexto do objeto SparkSQL que será responsável por executar as *query* do Spark com comandos SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x7f631dd59390>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui é a criação de um Dataframe com os dados que estamos lendo do arquivo CSV. Usamos o contexto do SparkSQL, mas ainda sim é um Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dadosSpark = sql.read.format(\"csv\").options(header='true').load('mtcars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dadosSpark.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dadosSpark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dadosSpark.select(\"model\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do dataframe **dadosSpark**, vamos registrar uma tabela temporária do SQL, chamada **Carros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dadosSpark.registerTempTable(\"carros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do motor do **SparkSQL** vamos escrever uma *query* em SQL que retornará todas as linhas e colunas da nossa base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql.sql(\"select count(0) from carros\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql.sql(\"select * from carros\").show(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql.sql(\"select cyl AS Cilindros, \\\n",
    "                round(avg(wt),2) AS PesoMedio \\\n",
    "         from carros group by cyl \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql.sql(\"select model from carros order by qsec desc\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E é possível converter em Dataframe e depois gerar visualizações com os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dados = sql.sql(\"select int(gear), float(wt), float(mpg) from carros\")\n",
    "df = dados.toPandas() \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "cores = {3:'tab:cyan',4:'tab:purple',5:'tab:green'}\n",
    "marcadores = {3:'^',4:'s',5:'D'}\n",
    "\n",
    "for cambio in df['gear'].unique():\n",
    "    tmp = df[df['gear'] == cambio]\n",
    "    plt.scatter(tmp['wt'], tmp['mpg'], color=cores[cambio], marker=marcadores[cambio], s=100)\n",
    "\n",
    "plt.title(\"Motor Trend car Road Test\")\n",
    "plt.suptitle(\"Dados de 1974  Motor Trend US Magazine\")\n",
    "plt.xlabel(\"Peso do Carro\")\n",
    "plt.ylabel( \"Milhas por Galão\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
