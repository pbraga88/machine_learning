{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Exercise 11 - Recurrent Neural Networks\n",
    "========\n",
    "\n",
    "A recurrent neural network (RNN) is a class of neural network that excels when your data can be treated as a sequence - such as text, music, speech recognition, connected handwriting, or data over a time period. \n",
    "\n",
    "RNN's can analyse or predict a word based on the previous words in a sentence - they allow a connection between previous information and current information.\n",
    "\n",
    "This exercise looks at implementing a LSTM RNN to generate new characters after learning from a large sample of text. LSTMs are a special type of RNN which dramatically improves the model’s ability to connect previous data to current data where there is a long gap.\n",
    "\n",
    "We will train an RNN model using a novel written by H. G. Wells - The Time Machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1\n",
    "------\n",
    "\n",
    "Let's start by loading our libraries and text file. This might take a few minutes.\n",
    "\n",
    "#### Run the cell below to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run this!\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "from keras.callbacks import LambdaCallback, ModelCheckpoint\n",
    "import numpy as np\n",
    "import random, sys, io, string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace the `<addFileName>` with `The Time Machine`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Time Traveller (for so it will be convenient to speak of him) was expounding a recondite matter to us. His pale grey eyes shone and twinkled, and his usually pale face was flushed and animated.\n",
      "text length: 174201 characters\n",
      "unique characters: 39\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# REPLACE THE <addFileName> BELOW WITH The Time Machine\n",
    "###\n",
    "text = io.open('../Data/The Time Machine.txt', encoding = 'UTF-8').read()\n",
    "###\n",
    "\n",
    "# Let's have a look at some of the text\n",
    "print(text[0:198])\n",
    "\n",
    "# This cuts out punctuation and make all the characters lower case\n",
    "text = text.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "# Character index dictionary\n",
    "charset = sorted(list(set(text)))\n",
    "index_from_char = dict((c, i) for i, c in enumerate(charset))\n",
    "char_from_index = dict((i, c) for i, c in enumerate(charset))\n",
    "\n",
    "print('text length: %s characters' %len(text))\n",
    "print('unique characters: %s' %len(charset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '0': 1, '1': 2, '2': 3, '3': 4, '5': 5, 'a': 6, 'b': 7, 'c': 8, 'd': 9, 'e': 10, 'f': 11, 'g': 12, 'h': 13, 'i': 14, 'j': 15, 'k': 16, 'l': 17, 'm': 18, 'n': 19, 'o': 20, 'p': 21, 'q': 22, 'r': 23, 's': 24, 't': 25, 'u': 26, 'v': 27, 'w': 28, 'x': 29, 'y': 30, 'z': 31, 'é': 32, 'ê': 33, 'î': 34, 'ï': 35, 'ô': 36, '—': 37, '‘': 38, '’': 39, '“': 40, '”': 41, '\\ufeff': 42}\n"
     ]
    }
   ],
   "source": [
    "# print(charset)\n",
    "print(index_from_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: '0', 2: '1', 3: '2', 4: '3', 5: '5', 6: 'a', 7: 'b', 8: 'c', 9: 'd', 10: 'e', 11: 'f', 12: 'g', 13: 'h', 14: 'i', 15: 'j', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'x', 30: 'y', 31: 'z', 32: 'é', 33: 'ê', 34: 'î', 35: 'ï', 36: 'ô', 37: '—', 38: '‘', 39: '’', 40: '“', 41: '”', 42: '\\ufeff'}\n"
     ]
    }
   ],
   "source": [
    "print(char_from_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:  \n",
    "```The Time Traveller (for so it will be convenient to speak of him) was expounding a recondite matter to us. His pale grey eyes shone and twinkled, and his usually pale face was flushed and animated.\n",
    "text length: 174201 characters\n",
    "unique characters: 39```\n",
    "\n",
    "Step 2\n",
    "-----\n",
    "\n",
    "Next we'll divide the text into sequences of 40 characters.\n",
    "\n",
    "Then for each sequence we'll make a training set - the following character will be the correct output for the test set.\n",
    "\n",
    "### In the cell below replace:\n",
    "#### 1. `<sequenceLength>` with `40`\n",
    "#### 2. `<step>` with `4`\n",
    "#### and then __run the code__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training sequences: 43541\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# REPLACE <sequenceLength> WITH 40 AND <step> WITH 4\n",
    "###\n",
    "sequence_length = 40\n",
    "step = 4\n",
    "###\n",
    "\n",
    "sequences = []\n",
    "target_chars = []\n",
    "for i in range(0, len(text) - sequence_length, step):\n",
    "    sequences.append([text[i: i + sequence_length]])\n",
    "    target_chars.append(text[i + sequence_length])\n",
    "print('number of training sequences:', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "`number of training sequences: 43541`\n",
    "\n",
    "#### Replace `<addSequences>` with `sequences` and run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot vectorise\n",
    "\n",
    "X = np.zeros((len(sequences), sequence_length, len(charset)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(charset)), dtype=np.bool)\n",
    "\n",
    "###\n",
    "# REPLACE THE <addSequences> BELOW WITH sequences\n",
    "###\n",
    "for n, sequence in enumerate(sequences):\n",
    "###\n",
    "    for m, character in enumerate(list(sequence[0])):\n",
    "        X[n, m, index_from_char[character]] = 1\n",
    "    y[n, index_from_char[target_chars[n]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False  True False ... False False False]\n",
      " ...\n",
      " [False  True False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [ True False False ... False False False]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3\n",
    "------\n",
    "\n",
    "Let's build our model, using a single LSTM layer of 128 units. We'll keep the model simple for now, so that training does not take too long.\n",
    "\n",
    "### In the cell below replace:\n",
    "#### 1. `<addLSTM>` with `LSTM`\n",
    "#### 2. `<addLayerSize>` with `128`\n",
    "#### 3. `<addSoftmaxFunction>` with `'softmax`\n",
    "#### and then __run the code__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "###\n",
    "# REPLACE THE <addLSTM> BELOW WITH LSTM (use uppercase) AND <addLayerSize> WITH 128\n",
    "###\n",
    "model.add(LSTM(128, input_shape = (X.shape[1], X.shape[2])))\n",
    "###\n",
    "\n",
    "###\n",
    "# REPLACE THE <addSoftmaxFunction> with 'softmax' (INCLUDING THE QUOTES)\n",
    "###\n",
    "model.add(Dense(y.shape[1], activation = 'softmax'))\n",
    "###\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below generates text at the end of an epoch (one training cycle). This allows us to see how the model is performing as it trains. If you're making a large neural network with a long training time it's useful to check in on the model as see if the text generating is legible as it trains, as overtraining may occur and the output of the model turn to nonsense.\n",
    "\n",
    "The code below will also save a model if it is the best performing model, so we can use it later.\n",
    "\n",
    "#### Run the code below, but don't change it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this, but do not edit.\n",
    "# It helps generate the text and save the model epochs.\n",
    "\n",
    "# Generate new text\n",
    "def on_epoch_end(epoch, _):\n",
    "    diversity = 0.5\n",
    "    print('\\n### Generating text with diversity %0.2f' %(diversity))\n",
    "\n",
    "    start = random.randint(0, len(text) - sequence_length - 1)\n",
    "    seed = text[start: start + sequence_length]\n",
    "    print('### Generating with seed: \"%s\"' %seed[:40])\n",
    "\n",
    "    output = seed[:40].lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    print(output, end = '')\n",
    "\n",
    "    for i in range(500):\n",
    "        x_pred = np.zeros((1, sequence_length, len(charset)))\n",
    "        for t, char in enumerate(output):\n",
    "            x_pred[0, t, index_from_char[char]] = 1.\n",
    "\n",
    "        predictions = model.predict(x_pred, verbose=0)[0]\n",
    "        exp_preds = np.exp(np.log(np.asarray(predictions).astype('float64')) / diversity)\n",
    "        next_index = np.argmax(np.random.multinomial(1, exp_preds / np.sum(exp_preds), 1))\n",
    "        next_char = char_from_index[next_index]\n",
    "\n",
    "        output = output[1:] + next_char\n",
    "\n",
    "        print(next_char, end = '')\n",
    "    print()\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "# Save the model\n",
    "checkpoint = ModelCheckpoint('../Models/model-epoch-{epoch:02d}.hdf5', \n",
    "                             monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will start the model to train. This may take a long time. Feel free to stop the training with the `square stop button` to the right of the `Run button` in the toolbar.\n",
    "\n",
    "Later in the exercise, we will load a pretrained model.\n",
    "\n",
    "### In the cell below replace:\n",
    "#### 1. `<addPrintCallback>` with `print_callback`\n",
    "#### 2. `<addCheckpoint>` with `checkpoint`\n",
    "#### and then __run the code__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "340/341 [============================>.] - ETA: 0s - loss: 2.7531\n",
      "### Generating text with diversity 0.50\n",
      "### Generating with seed: \"uld perceive no definite reason i rememb\"\n",
      "uld perceive no definite reason i remembih nai n tae the the thee t ai san e t the anin the se inle cin the that ihol  in t ipeis she ro then thit toaron thas the the tton tal tai s the aoe e ate cat in t f aha t enre oa tad at thele thent fin on e the t aor ais in int ail then  ceise an s aae t t toe sa ist oad the  aon o pcos she the d owat aos awal  atheo fen there the he ther the s d oure thin thad rhe brd an there ia g e ale ther sin t as s tke ta hee then  he f ore thends ahai n d then tee as ans ace  anwe tre aires ean iol nt w\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.75287, saving model to ../Models/model-epoch-01.hdf5\n",
      "341/341 [==============================] - 46s 134ms/step - loss: 2.7529\n",
      "Epoch 2/3\n",
      "340/341 [============================>.] - ETA: 0s - loss: 2.3685\n",
      "### Generating text with diversity 0.50\n",
      "### Generating with seed: \"e but there was an altogether new elemen\"\n",
      "e but there was an altogether new elemeng of ant we at ou thed iung in thal the dathe has ur os on the duthe the the the thet mereuthe ind he the was thee tha e hene the as of the tithe of on ind then aig an re thend in the tho th muthe we theg the the ind the that in the the the de she the whe ton the the mat the ther the the  anod mhat the pare me tad shan the ti ghe the thy he thad the the thit te the she the sathed and the the has in the ind y the the hind sod the ead was the the ans the hand wace he thit ound he an wa s and shal \n",
      "\n",
      "Epoch 00002: loss improved from 2.75287 to 2.36828, saving model to ../Models/model-epoch-02.hdf5\n",
      "341/341 [==============================] - 46s 135ms/step - loss: 2.3683\n",
      "Epoch 3/3\n",
      "340/341 [============================>.] - ETA: 0s - loss: 2.2281\n",
      "### Generating text with diversity 0.50\n",
      "### Generating with seed: \"ion i pushed my explorations here and th\"\n",
      "ion i pushed my explorations here and the the sor the uron it ar it the tore ha s on the sith ufd shen was and mast and mat on ald for thare in mus ar the tild and the thi hin in the in and fare mas the far init and wat in in th mathe ind the cour the the thow ind ind the seat the sare the dore far the wat he anca tore tor the mare tor ind the hed the lad ine on on ther of the wast and an the rad the ther lued of and ald ais in and mat ars li he the  or the thers and the sonco seat and re the me in ind the the warel and or of the the \n",
      "\n",
      "Epoch 00003: loss improved from 2.36828 to 2.22835, saving model to ../Models/model-epoch-03.hdf5\n",
      "341/341 [==============================] - 47s 138ms/step - loss: 2.2284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fccb0230c50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "# REPLACE <addPrintCallback> WITH print_callback AND <addCheckpoint> WITH checkpoint\n",
    "###\n",
    "model.fit(X, y, batch_size = 128, epochs = 3, callbacks = [print_callback, checkpoint])\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output won't appear to be very good. But then, this dataset is small, and we have trained it only for a short time using a rather small RNN. How might it look if we upscaled things?\n",
    "\n",
    "Step 5\n",
    "------\n",
    "\n",
    "We could improve our model by:\n",
    "* Having a larger training set.\n",
    "* Increasing the number of LSTM units.\n",
    "* Training it for longer\n",
    "* Experimenting with difference activation functions, optimization functions etc\n",
    "\n",
    "Training this would still take far too long on most computers to see good results - so we've trained a model already for you.\n",
    "\n",
    "This model uses a different dataset - a few of the King Arthur tales pasted together. The model used:\n",
    "* sequences of 50 characters\n",
    "* Two LSTM layers (512 units each)\n",
    "* A dropout of 0.5 after each LSTM layer\n",
    "* Only 30 epochs (we'd recomend 100-200)\n",
    "\n",
    "Let's try importing this model that has already been trained.\n",
    "\n",
    "#### Replace `<addLoadModel>` with `load_model` and run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model... model loaded\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "print(\"loading model... \", end = '')\n",
    "\n",
    "###\n",
    "# REPLACE <addLoadModel> BELOW WITH load_model\n",
    "###\n",
    "model = load_model('../Models/arthur-model-epoch-30.hdf5')\n",
    "###\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam')\n",
    "###\n",
    "\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0-rc1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6\n",
    "-------\n",
    "\n",
    "Now let's use this model to generate some new text!\n",
    "\n",
    "#### Replace `<addFilePath>` with `'Data/Arthur tales.txt'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text length: 3645951 characters\n",
      "unique characters: 43\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# REPLACE <addFilePath> BELOW WITH 'Data/Arthur tales.txt' (INCLUDING THE QUOTATION MARKS)\n",
    "###\n",
    "text = io.open('../Data/Arthur tales.txt', encoding='UTF-8').read()\n",
    "###\n",
    "\n",
    "# Cut out punctuation and make lower case\n",
    "text = text.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "# Character index dictionary\n",
    "charset = sorted(list(set(text)))\n",
    "index_from_char = dict((c, i) for i, c in enumerate(charset))\n",
    "char_from_index = dict((i, c) for i, c in enumerate(charset))\n",
    "\n",
    "print('text length: %s characters' %len(text))\n",
    "print('unique characters: %s' %len(charset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the cell below replace:\n",
    "#### 1. `<sequenceLength>` with `50`\n",
    "#### 2. `<writeSentence>` with a sentence of your own, at least 50 characters long.\n",
    "#### 3. `<numCharsToGenerate>` with the number of characters you want to generate (choose a large number, like 1500)\n",
    "#### and then __run the code__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Generating text with diversity 0.50\n",
      "### Generating with seed: \"modelo capaz de prever com certo grau de\"\n",
      "modelo capaz de prever com certo grau de eficiêncien and made in the forest and they made the sword so that it was a little thought of and in the forest and all the king and the blood of the side was a great wounded knight of the round table and there was a good man of sir launcelot and so sir launcelot came into the castle and with the scabbard sir tristram and they made a but the head of the river and he had done then sir tristram and his spear and sir gawaine and sir launcelot was a mighty and then was it before again to the castle their arms and they arrived the king and the king and the sword and the knight came to a corcame then sir tristram and all his spear was a rich and so she did so so that he was when he was wroth and so recovered the horses and they came to the court and they asked him that he was come to the palace  and the horses was wroth and overthrew him to the earth then sir lancelot smote down sir gawain and sir launcelot and all his horse they came with the son of dry he took his horse and the red knight of the round table then said sir tristram i will be there and i shall not take him of many dolorous man and worship as ye have asked a man of morgan le fay great pain sir said the king me commandment that i shall tell you as ye love i will be hand of this country and answered the king how me let us as thou wilt never see and therewith he thought he knew him suffer that he fell down to the chamber and there he saw sir tristram and he came to the water and there he saw a great child and the barons and ther\n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "\n",
    "diversity = 0.5\n",
    "print('\\n### Generating text with diversity %0.2f' %(diversity))\n",
    "\n",
    "###\n",
    "# REPLACE <sequenceLength> BELOW WITH 50\n",
    "###\n",
    "sequence_length = 50\n",
    "###\n",
    "\n",
    "# Next we'll make a starting point for our text generator\n",
    "\n",
    "###\n",
    "# REPLACE <writeSentence> WITH A SENTENCE OF AT LEAST 50 CHARACTERS\n",
    "###\n",
    "seed = \"modelo capaz de prever, com certo grau de eficiência, quando um módulo poderá vir a apresentar algum tipo de falha. O objeto de estudo dessa dissertação é o disco rígido externo contudo, com o que aqui é proposto, não tenho dúvidas da possibilidade de generalizar a aplicação para diferentes camadas do sistema\"\n",
    "###\n",
    "\n",
    "seed = seed.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "###\n",
    "# OR, ALTERNATIVELY, UNCOMMENT THE FOLLOWING TWO LINES AND GRAB A RANDOM STRING FROM THE TEXT FILE\n",
    "###\n",
    "\n",
    "#start = random.randint(0, len(text) - sequence_length - 1)\n",
    "#seed = text[start: start + sequence_length]\n",
    "\n",
    "###\n",
    "\n",
    "print('### Generating with seed: \"%s\"' %seed[:40])\n",
    "\n",
    "output = seed[:sequence_length].lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "print(output, end = '')\n",
    "\n",
    "###\n",
    "# REPLACE THE <numCharsToGenerate> BELOW WITH THE NUMBER OF CHARACTERS WE WISH TO GENERATE, e.g. 1500\n",
    "###\n",
    "for i in range(1500):\n",
    "###\n",
    "    x_pred = np.zeros((1, sequence_length, len(charset)))\n",
    "    for t, char in enumerate(output):\n",
    "        x_pred[0, t, index_from_char[char]] = 1.\n",
    "\n",
    "    predictions = model.predict(x_pred, verbose=0)[0]\n",
    "    exp_preds = np.exp(np.log(np.asarray(predictions).astype('float64')) / diversity)\n",
    "    next_index = np.argmax(np.random.multinomial(1, exp_preds / np.sum(exp_preds), 1))\n",
    "    next_char = char_from_index[next_index]\n",
    "\n",
    "    output = output[1:] + next_char\n",
    "\n",
    "    print(next_char, end = '')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does it look? Does it seem intelligible?\n",
    "\n",
    "Conclusion\n",
    "--------\n",
    "\n",
    "We have trained an RNN that learns to predict characters based on a text sequence. We have trained a lightweight model from scratch, as well as imported a pre-trained model and generated new text from that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
